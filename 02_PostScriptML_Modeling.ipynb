{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostScriptML: Modeling Notebook\n",
    "## by Dolci Key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import pickle\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "# AWS  Sagemaker Needed using AWS Sagemaker Notebook Instance\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from tensorflow.python.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-postscriptml' # AWS S3 Bucket path to dataset\n",
    "train_instance_type = 'ml.m4.xlarge' # AWS EC2 Instance used for training\n",
    "deploy_instance_type = 'ml.m4.xlarge' # AWS EC2 Instance used for deployment\n",
    "hyperparameters = {'learning_rate': 0.001, 'decay': 0.0001}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = 's3://{}/TRAIN'.format(bucket) # Path to training data \n",
    "test_input_path = 's3://{}/TEST'.format(bucket) # Path to test data\n",
    "validation_input_path = 's3://{}/VALIDATION'.format(bucket) # Path to validation data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "  entry_point=os.path.join(os.path.dirname('__file__'), \"SCRIPTS/start_script_i.py\"),             # Your entry script\n",
    "  role=role,\n",
    "  framework_version='1.12.0',               # TensorFlow's version\n",
    "  training_steps = 100,\n",
    "  evaluation_steps = 30, \n",
    "  hyperparameters=hyperparameters,\n",
    "  train_instance_count=1,                   # \"The number of GPUs instances to use\"\n",
    "  train_instance_type=train_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "2020-09-22 21:43:39 Starting - Starting the training job...\n",
      "2020-09-22 21:43:40 Starting - Launching requested ML instances......\n",
      "2020-09-22 21:45:03 Starting - Preparing the instances for training......\n",
      "2020-09-22 21:45:52 Downloading - Downloading input data...\n",
      "2020-09-22 21:46:39 Training - Training image download completed. Training in progress..\u001b[34m2020-09-22 21:46:39,573 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:39,573 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:39,589 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-22-21-43-38-480/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,549 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,549 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,549 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,549 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,549 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,549 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,550 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:42,849 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:45,707 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f26be213dd0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-22-21-43-38-480/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:45,731 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:45,731 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[34mFound 1957 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:47,064 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,055 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,056 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-22-21-43-38-480/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,056 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-22-21-43-38-480/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,056 INFO - tensorflow - Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,283 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,478 INFO - tensorflow - Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,666 INFO - tensorflow - Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:48,835 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:49,026 INFO - tensorflow - Warm-starting variable: conv2d_3/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:49,249 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:49,414 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:49,594 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:49,821 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:50,006 INFO - tensorflow - Warm-starting variable: conv2d_3/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:50,173 INFO - tensorflow - Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:50,347 INFO - tensorflow - Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:50,530 INFO - tensorflow - Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:50,699 INFO - tensorflow - Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:50,868 INFO - tensorflow - Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:51,043 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:52,979 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:54,718 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:46:54,729 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:47:04,645 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-22-21-43-38-480/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-09-22 21:47:12,840 INFO - tensorflow - loss = 0.6575143, step = 1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "estimator.fit({'training': train_input_path, 'eval': validation_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
