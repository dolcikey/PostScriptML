{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostScriptML: Modeling Notebook\n",
    "### by Dolci Key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In following this notebook, you should be able to run an Amazon SageMaker Instance. This notebook is mainly a function in which I have used to run scripts (the model code/specifications) through. Please review the python scripts in the SCRIPTS folder of the repo for further insignt into the model parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import pickle\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a AWS SageMaker Instance\n",
    "Import specific libraries in an AWS SageMaker Notebook Instance. This will not work in a normal Jupyter Notebook environment. Once you have the libraries, you will start a session and connect your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "# AWS  Sagemaker Needed using AWS Sagemaker Notebook Instance\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from tensorflow.python.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Bucket Connection\n",
    "Here I am connecting my S3 bucket. You MUST have 'sagemaker-' as the prefix on the name of your bucket for this to work. Please note that once the bucket is made, you cannot rename the bucket, however, you can move the data from one bucket to another if you make this mistake. \n",
    "\n",
    "A special thanks to Aren Carpenter for helping troubleshoot issues with the S3 buckets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-postscriptml' # AWS S3 Bucket path to dataset\n",
    "train_instance_type = 'ml.m4.xlarge' # AWS EC2 Instance used for training\n",
    "deploy_instance_type = 'ml.m4.xlarge' # AWS EC2 Instance used for deployment\n",
    "hyperparameters = {'learning_rate': 0.001, 'decay': 0.0001}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = 's3://{}/TRAIN'.format(bucket) # Path to training data \n",
    "\n",
    "# my test and validaiton was mixed up, and because of this data leakage did occur, \n",
    "# so I have switched these to prevent leakage for the time being. \n",
    "# post MVP presentation, I will be reallocating these differently. \n",
    "\n",
    "validation_input_path = 's3://{}/TEST'.format(bucket) # Path to test data\n",
    "test_input_path = 's3://{}/VALIDATION'.format(bucket) # Path to validation data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Models with Scripts \n",
    "\n",
    "Once I had my data set up, I created the model using TensorFlow. These steps varied when using Python 3 or 2.7. Using 2.7 I was able to list the training and evaluation steps, otherwise in python 3, the version of python had to be specified and training/evaluation steps had to be moved to my hyperparameter dictionary. \n",
    "\n",
    "I read in the script from my SCRIPTS folder on my repo. There you can find each Script that I tested. I then logged each accuracy and also the highest step accuracy from the evaluation to keep track of my modeling scripts. \n",
    "\n",
    "I utilized the tutorial on Amazon SageMaker and scripting from Paul Breton to base my scripts and models on for AWS. \n",
    "\n",
    "## Metrics\n",
    "\n",
    "I used binary cross-entropy as the loss function and accuracy (binary accuracy) as the metrics for this CNN. \n",
    "My next goals after MVP will be incorporating Sigmoid activation fuction to give feedback on the image in additiona to coding for other metrics such as recall that will help minimize the false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TensorFlow(\n",
    "  entry_point=os.path.join(os.path.dirname('__file__'), \"SCRIPTS/model_script_iii.py\"), # Your entry script\n",
    "  role=role,\n",
    "  framework_version='1.12.0', # TensorFlow's version\n",
    "  training_steps = 90,\n",
    "  evaluation_steps = 30, \n",
    "  hyperparameters=hyperparameters, # For python 3 you have to specify evaluation and training steps in the above hyperparameters\n",
    "  train_instance_count=1,   # \"The number of GPUs instances to use\"\n",
    "  train_instance_type=train_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "2020-09-23 05:07:46 Starting - Starting the training job...\n",
      "2020-09-23 05:07:49 Starting - Launching requested ML instances......\n",
      "2020-09-23 05:09:11 Starting - Preparing the instances for training......\n",
      "2020-09-23 05:10:07 Downloading - Downloading input data...\n",
      "2020-09-23 05:10:47 Training - Downloading the training image...\n",
      "2020-09-23 05:11:07 Training - Training image download completed. Training in progress.\u001b[34m2020-09-23 05:11:07,915 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:07,916 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:07,932 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,796 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,796 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,797 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,797 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,797 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,797 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:11,797 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:12,179 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:15,055 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b80544dd0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:15,082 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:15,083 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[34mFound 1957 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:16,475 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:17,497 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:17,498 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:17,498 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:17,498 INFO - tensorflow - Warm-starting variable: conv2d_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:17,706 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:17,893 INFO - tensorflow - Warm-starting variable: dense_2/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:18,084 INFO - tensorflow - Warm-starting variable: conv2d_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:18,277 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:18,463 INFO - tensorflow - Warm-starting variable: conv2d_3/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:18,731 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:18,957 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:19,135 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:19,396 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:19,588 INFO - tensorflow - Warm-starting variable: conv2d_3/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:19,799 INFO - tensorflow - Warm-starting variable: dense_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:20,021 INFO - tensorflow - Warm-starting variable: conv2d/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:20,263 INFO - tensorflow - Warm-starting variable: conv2d_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:20,463 INFO - tensorflow - Warm-starting variable: conv2d_2/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:20,646 INFO - tensorflow - Warm-starting variable: conv2d/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:20,846 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:22,984 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:24,821 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:24,835 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:34,760 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:11:43,165 INFO - tensorflow - loss = 0.90296507, step = 1\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:25,902 INFO - tensorflow - Saving checkpoints for 90 into s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34mFound 1957 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:32,319 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:32,761 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:32,786 INFO - tensorflow - Starting evaluation at 2020-09-23-05:16:32\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:32,990 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:33,078 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/model.ckpt-90\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:33,587 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:33,602 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:36,716 INFO - tensorflow - Evaluation [3/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:39,122 INFO - tensorflow - Evaluation [6/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:41,586 INFO - tensorflow - Evaluation [9/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:43,994 INFO - tensorflow - Evaluation [12/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:46,536 INFO - tensorflow - Evaluation [15/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:48,943 INFO - tensorflow - Evaluation [18/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:51,406 INFO - tensorflow - Evaluation [21/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:53,810 INFO - tensorflow - Evaluation [24/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:56,291 INFO - tensorflow - Evaluation [27/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:58,699 INFO - tensorflow - Evaluation [30/30]\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:58,731 INFO - tensorflow - Finished evaluation at 2020-09-23-05:16:58\u001b[0m\n",
      "\u001b[34m2020-09-23 05:16:58,731 INFO - tensorflow - Saving dict for global step 90: accuracy = 0.9375, binary_accuracy = 0.9375, global_step = 90, loss = 0.34513915\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:02,002 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 90: s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/model.ckpt-90\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:03,889 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,048 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,049 INFO - tensorflow - Signatures INCLUDED in export for Eval: None\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,049 INFO - tensorflow - Signatures INCLUDED in export for Classify: None\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,049 INFO - tensorflow - Signatures INCLUDED in export for Regress: None\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,049 INFO - tensorflow - Signatures INCLUDED in export for Predict: ['serving_default']\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,049 INFO - tensorflow - Signatures INCLUDED in export for Train: None\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,171 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/model.ckpt-90\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,728 WARNING - tensorflow - From /usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py:1046: calling add_meta_graph_and_variables (from tensorflow.python.saved_model.builder_impl) with legacy_init_op is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mPass your op to the equivalent parameter main_op instead.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,728 INFO - tensorflow - Assets added to graph.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:04,728 INFO - tensorflow - No assets to write.\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:06,021 INFO - tensorflow - SavedModel written to: s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-23-05-07-45-472/checkpoints/export/Servo/1600838223/saved_model.pb\u001b[0m\n",
      "\u001b[34m2020-09-23 05:17:06,099 INFO - tensorflow - Loss for final step: 0.000115605115.\u001b[0m\n",
      "\n",
      "2020-09-23 05:17:17 Uploading - Uploading generated training model\n",
      "2020-09-23 05:17:17 Completed - Training job completed\n",
      "\u001b[34m2020-09-23 05:17:06,553 INFO - tf_container - Downloaded saved model at /opt/ml/model/export/Servo/1600838223\u001b[0m\n",
      "Training seconds: 430\n",
      "Billable seconds: 430\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "model.fit({'training': train_input_path, 'evaluation': validation_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
