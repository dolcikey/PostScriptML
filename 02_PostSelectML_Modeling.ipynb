{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostScriptML: Modeling Notebook\n",
    "### by Dolci Key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In following this notebook, you should be able to run an Amazon SageMaker Instance. This notebook is mainly a function in which I have used to run scripts (the model code/specifications) through. \n",
    " \n",
    "Please review the python scripts in the SCRIPTS folder of the repo for further insignt into the model parameters. Code was referenced from Paul Breton's code along of AWS SageMaker on Medium.com. He suggested using the scripts which are helpful in keeping models separated. AWS also stores the models in the S3 Bucket after they have finished running. \n",
    "\n",
    "This modeling process was iterative in that, I started with the vanilla baseline script, made improvements, added additional updates, ran the mode_script_ii, and then worked each iteratively from that one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import pickle\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting a AWS SageMaker Instance\n",
    "Import specific libraries in an AWS SageMaker Notebook Instance. This will not work in a normal Jupyter Notebook environment. Once you have the libraries, you will start a session and connect your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS  Sagemaker Needed using AWS Sagemaker Notebook Instance\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from tensorflow.python.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 Bucket Connection\n",
    "Here I am connecting my S3 bucket. You MUST have 'sagemaker-' as the prefix on the name of your bucket for this to work. Please note that once the bucket is made, you cannot rename the bucket, however, you can move the data from one bucket to another if you make this mistake. \n",
    "\n",
    "A special thanks to Aren Carpenter for helping troubleshoot issues with the S3 buckets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'sagemaker-postscriptml' # AWS S3 Bucket path to dataset\n",
    "train_instance_type = 'ml.m4.xlarge' # AWS EC2 Instance used for training\n",
    "deploy_instance_type = 'ml.m4.xlarge' # AWS EC2 Instance used for deployment\n",
    "hyperparameters = {'learning_rate': 0.001, 'decay': 0.0001}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_path = 's3://{}/TRAIN'.format(bucket) # Path to training data \n",
    "test_input_path = 's3://{}/TEST'.format(bucket) # Path to test data\n",
    "validation_input_path = 's3://{}/VALIDATION'.format(bucket) # Path to validation data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Models with Scripts \n",
    "\n",
    "Once I had my data set up, I created the model using TensorFlow. These steps varied when using Python 3 or 2.7. Using 2.7 I was able to list the training and evaluation steps, otherwise in python 3, the version of python had to be specified and training/evaluation steps had to be moved to my hyperparameter dictionary. \n",
    "\n",
    "I read in the script from my SCRIPTS folder on my repo. There you can find each Script that I tested. I then logged each accuracy and also the highest step accuracy from the evaluation to keep track of my modeling scripts. \n",
    "\n",
    "I utilized the tutorial on Amazon SageMaker and scripting from Paul Breton to base my scripts and models on for AWS. \n",
    "\n",
    "## Metrics\n",
    "\n",
    "I used binary cross-entropy as the loss function and accuracy (binary accuracy) as the metrics for this CNN. I worked to minimize loss as much as I could as the baseline had a decent accuracy, but the loss was 1.0. \n",
    "\n",
    "So far the best model is my model_script_iii which has a loss of .343 and a binary accuracy score of .9375.\n",
    "\n",
    "My next goals after MVP will be incorporating Sigmoid activation fuction to give feedback on the image in additiona to coding for other metrics such as recall that will help minimize the false negatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TensorFlow(\n",
    "  entry_point=os.path.join(os.path.dirname('__file__'), \"SCRIPTS/vanilla_ii.py\"), # Your entry script\n",
    "  role=role,\n",
    "  framework_version='1.12.0', # TensorFlow's version\n",
    "  training_steps = 100,\n",
    "  evaluation_steps = 30, \n",
    "  hyperparameters=hyperparameters, # For python 3 you have to specify evaluation and training steps in the above hyperparameters\n",
    "  train_instance_count=1,   # \"The number of GPUs instances to use\"\n",
    "  train_instance_type=train_instance_type,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the model \n",
    "\n",
    "After running the code block, you will see: \n",
    "    \n",
    "Training ...\n",
    "2020-09-23 05:07:46 Starting - Starting the training job...\n",
    "2020-09-23 05:07:49 Starting - Launching requested ML instances......\n",
    "2020-09-23 05:09:11 Starting - Preparing the instances for training......\n",
    "2020-09-23 05:10:07 Downloading - Downloading input data...\n",
    "2020-09-23 05:10:47 Training - Downloading the training image...\n",
    "2020-09-23 05:11:07 Training - Training image download completed. Training in progress.\n",
    "        \n",
    "This is starting and will then start to run the model. If it errors out, it will give a traceback at the end, so make sure to keep watching the code until you see steps running. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "2020-09-29 00:12:58 Starting - Starting the training job...\n",
      "2020-09-29 00:13:00 Starting - Launching requested ML instances......\n",
      "2020-09-29 00:14:08 Starting - Preparing the instances for training......\n",
      "2020-09-29 00:14:59 Downloading - Downloading input data...\n",
      "2020-09-29 00:15:45 Training - Downloading the training image..\u001b[34m2020-09-29 00:16:04,966 INFO - root - running container entrypoint\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:04,967 INFO - root - starting train task\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:04,997 INFO - container_support.training - Training starting\u001b[0m\n",
      "\u001b[34mDownloading s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/source/sourcedir.tar.gz to /tmp/script.tar.gz\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,968 INFO - tf_container - ----------------------TF_CONFIG--------------------------\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,968 INFO - tf_container - {\"environment\": \"cloud\", \"cluster\": {\"master\": [\"algo-1:2222\"]}, \"task\": {\"index\": 0, \"type\": \"master\"}}\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,969 INFO - tf_container - ---------------------------------------------------------\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,969 INFO - tf_container - creating RunConfig:\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,969 INFO - tf_container - {'save_checkpoints_secs': 300}\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,969 INFO - tensorflow - TF_CONFIG environment variable: {u'environment': u'cloud', u'cluster': {u'master': [u'algo-1:2222']}, u'task': {u'index': 0, u'type': u'master'}}\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:08,969 INFO - tf_container - invoking the user-provided keras_model_fn\u001b[0m\n",
      "\u001b[34m2020-09-29 00:16:09,164 INFO - tensorflow - Using the Keras model provided.\u001b[0m\n",
      "\n",
      "2020-09-29 00:16:04 Training - Training image download completed. Training in progress.\u001b[34m2020-09-29 00:17:26,920 INFO - tensorflow - Using config: {'_save_checkpoints_secs': 300, '_keep_checkpoint_max': 5, '_task_type': u'master', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f480af96fd0>, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_evaluation_master': '', '_eval_distribute': None, '_train_distribute': None, '_session_config': device_filters: \"/job:ps\"\u001b[0m\n",
      "\u001b[34mdevice_filters: \"/job:master\"\u001b[0m\n",
      "\u001b[34mallow_soft_placement: true\u001b[0m\n",
      "\u001b[34mgraph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34m, '_global_id_in_cluster': 0, '_is_chief': True, '_protocol': None, '_save_checkpoints_steps': None, '_experimental_distribute': None, '_save_summary_steps': 100, '_model_dir': u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints', '_master': ''}\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:26,941 INFO - tensorflow - Not using Distribute Coordinator.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:26,941 INFO - tensorflow - Skip starting Tensorflow server as there is only one node in the cluster.\u001b[0m\n",
      "\u001b[34mFound 1954 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:28,302 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:28,838 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:28,838 INFO - tensorflow - Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from=u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:28,838 INFO - tensorflow - Warm-starting from: (u's3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints/keras/keras_model.ckpt',)\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:28,839 INFO - tensorflow - Warm-starting variable: dense/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:29,019 INFO - tensorflow - Warm-starting variable: inputs/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:29,231 INFO - tensorflow - Warm-starting variable: inputs/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:29,419 INFO - tensorflow - Warm-starting variable: dense_1/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:29,733 INFO - tensorflow - Warm-starting variable: dense_1/bias; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:29,932 INFO - tensorflow - Warm-starting variable: dense/kernel; prev_var_name: Unchanged\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:30,165 INFO - tensorflow - Create CheckpointSaverHook.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:32,261 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:52,076 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:17:52,084 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:18:01,767 INFO - tensorflow - Saving checkpoints for 0 into s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:20:13,287 INFO - tensorflow - loss = 0.6404591, step = 1\u001b[0m\n",
      "\u001b[34m2020-09-29 00:24:56,061 INFO - tensorflow - Saving checkpoints for 100 into s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints/model.ckpt.\u001b[0m\n",
      "\u001b[34mFound 1954 images belonging to 2 classes.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:15,068 INFO - tensorflow - Calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:15,467 INFO - tensorflow - Done calling model_fn.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:15,490 INFO - tensorflow - Starting evaluation at 2020-09-29-00:27:15\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:15,569 INFO - tensorflow - Graph was finalized.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:15,646 INFO - tensorflow - Restoring parameters from s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:30,902 INFO - tensorflow - Running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:30,912 INFO - tensorflow - Done running local_init_op.\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:33,583 INFO - tensorflow - Evaluation [3/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:35,730 INFO - tensorflow - Evaluation [6/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:37,844 INFO - tensorflow - Evaluation [9/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:39,978 INFO - tensorflow - Evaluation [12/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:42,106 INFO - tensorflow - Evaluation [15/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:44,235 INFO - tensorflow - Evaluation [18/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:46,371 INFO - tensorflow - Evaluation [21/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:48,477 INFO - tensorflow - Evaluation [24/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:50,684 INFO - tensorflow - Evaluation [27/30]\u001b[0m\n",
      "\n",
      "2020-09-29 00:28:06 Uploading - Uploading generated training model\n",
      "2020-09-29 00:28:06 Failed - Training job failed\n",
      "\u001b[34m2020-09-29 00:27:52,787 INFO - tensorflow - Evaluation [30/30]\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:52,809 INFO - tensorflow - Finished evaluation at 2020-09-29-00:27:52\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:52,809 INFO - tensorflow - Saving dict for global step 100: accuracy = 0.8125, global_step = 100, loss = 3.005669\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:56,039 INFO - tensorflow - Saving 'checkpoint_path' summary for global step 100: s3://sagemaker-us-east-2-997425579135/sagemaker-tensorflow-2020-09-29-00-12-57-911/checkpoints/model.ckpt-100\u001b[0m\n",
      "\u001b[34m2020-09-29 00:27:57,837 ERROR - container_support.training - uncaught exception during training: 'DType' object has no attribute 'reshape'\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\n",
      "    fw.train()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 177, in train\n",
      "    train_wrapper.train()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 73, in train\n",
      "    tf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\n",
      "    return executor.run()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 637, in run\n",
      "    getattr(self, task_to_run)()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 674, in run_master\n",
      "    self._start_distributed_training(saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 788, in _start_distributed_training\n",
      "    saving_listeners=saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 354, in train\n",
      "    loss = self._train_model(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1209, in _train_model\n",
      "    return self._train_model_default(input_fn, hooks, saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1243, in _train_model_default\n",
      "    saving_listeners)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1473, in _train_with_estimator_spec\n",
      "    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 783, in __exit__\n",
      "    self._close_internal(exception_type)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 816, in _close_internal\n",
      "    h.end(self._coordinated_creator.tf_sess)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 588, in end\n",
      "    self._save(session, last_step)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 607, in _save\n",
      "    if l.after_save(session, step):\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 517, in after_save\n",
      "    self._evaluate(global_step_value)  # updates self.eval_result\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 537, in _evaluate\n",
      "    self._evaluator.evaluate_and_export())\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 924, in evaluate_and_export\n",
      "    is_the_final_export)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 957, in _export_eval_result\n",
      "    is_the_final_export=is_the_final_export))\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/exporter.py\", line 472, in export\n",
      "    is_the_final_export)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/exporter.py\", line 126, in export\n",
      "    strip_default_attrs=self._strip_default_attrs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 663, in export_savedmodel\n",
      "    mode=model_fn_lib.ModeKeys.PREDICT)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 789, in _export_saved_model_for_mode\n",
      "    strip_default_attrs=strip_default_attrs)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 909, in _export_all_saved_models\n",
      "    mode=model_fn_lib.ModeKeys.PREDICT)\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 979, in _add_meta_graph_for_mode\n",
      "    input_receiver = input_receiver_fn()\n",
      "  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 129, in <lambda>\n",
      "    serving_input_receiver_fn = lambda: self.customer_script.serving_input_fn(self.customer_params)\n",
      "  File \"/opt/ml/code/vanilla_ii.py\", line 40, in serving_input_fn\n",
      "    tensor = tf.placeholder(tf.float32.reshape((-1,1)), shape=[None, HEIGHT, WIDTH, DEPTH])\u001b[0m\n",
      "\u001b[34mAttributeError: 'DType' object has no attribute 'reshape'\n",
      "\n",
      "\u001b[0m\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job sagemaker-tensorflow-2020-09-29-00-12-57-911: Failed. Reason: AlgorithmError: uncaught exception during training: 'DType' object has no attribute 'reshape'\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\n    fw.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 177, in train\n    train_wrapper.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 73, in train\n    tf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\n    return executor.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 637, in run\n    getattr(self, task_to_run)()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 674, in run_master\n    self._start_distributed_training(saving_listeners=saving_lis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ae29e5eeaece>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_input_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'evaluation'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalidation_input_path\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/tensorflow/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config, run_tensorboard_locally)\u001b[0m\n\u001b[1;32m    481\u001b[0m                 \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m             \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/tensorflow/estimator.pyc\u001b[0m in \u001b[0;36mfit_super\u001b[0;34m()\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfit_super\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorFlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_tensorboard_locally\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwait\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/estimator.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;31m# If logs are requested, call logs_for_jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"None\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/session.pyc\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type)\u001b[0m\n\u001b[1;32m   3075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3076\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3077\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TrainingJobStatus\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3078\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/sagemaker/session.pyc\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   2669\u001b[0m                 ),\n\u001b[1;32m   2670\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Stopped\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2671\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2672\u001b[0m             )\n\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job sagemaker-tensorflow-2020-09-29-00-12-57-911: Failed. Reason: AlgorithmError: uncaught exception during training: 'DType' object has no attribute 'reshape'\nTraceback (most recent call last):\n  File \"/usr/local/lib/python2.7/dist-packages/container_support/training.py\", line 36, in start\n    fw.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/train_entry_point.py\", line 177, in train\n    train_wrapper.train()\n  File \"/usr/local/lib/python2.7/dist-packages/tf_container/trainer.py\", line 73, in train\n    tf.estimator.train_and_evaluate(estimator=estimator, train_spec=train_spec, eval_spec=eval_spec)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 471, in train_and_evaluate\n    return executor.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 637, in run\n    getattr(self, task_to_run)()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 674, in run_master\n    self._start_distributed_training(saving_listeners=saving_lis"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "model.fit({'training': train_input_path, 'evaluation': validation_input_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p27",
   "language": "python",
   "name": "conda_tensorflow_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
