{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PostSelecttML: Modeling Notebook Locally Run Modeling\n",
    "### by Dolci Key "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In following this notebook, I will run the current best model locally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers, metrics\n",
    "from tensorflow.keras.preprocessing import image, image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.metrics import Accuracy, Recall\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "import pydot\n",
    "import graphviz\n",
    "\n",
    "import pickle\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "import os\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data \n",
    "\n",
    "Here we have the train, validation, and hold out set directories and then the paths to the reject(X) and select(y/target). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "\n",
    "train_dir = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/TRAIN'\n",
    "\n",
    "# Split X and Y if needed \n",
    "train_x = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/TRAIN/reject'\n",
    "train_y = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/TRAIN/select'\n",
    "\n",
    "# Validation \n",
    "validation_dir = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/VALIDATION'\n",
    "\n",
    "# Split X and Y if needed \n",
    "test_x = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/VALIDATION/reject'\n",
    "test_y = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/VALIDATION/select'\n",
    "\n",
    "# Test/Hold Out Set \n",
    "\n",
    "test_dir = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/TEST'\n",
    "\n",
    "# Split X and Y if needed \n",
    "hold_x = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/TEST/reject'\n",
    "hold_y = '/Volumes/DOLCI KEY 2019/Neural Network/compressed/TEST/select'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Training, Validation, and Test sets. \n",
    "\n",
    "for the training set, we will use the horizontal_flip to augment the minority class as well as adding zoom range up to 30%. We have included the target size of the images which are 500,333 pixels each, set the color mode to RGB (color), and the class mode is binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1954 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Training\n",
    "train_set = image.ImageDataGenerator(rescale = 1/255, horizontal_flip = True, zoom_range = .3).flow_from_directory(train_dir,\n",
    "                                                                  target_size = (500,333), \n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 698 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation Set\n",
    "validation_set = image.ImageDataGenerator(rescale = 1/255).flow_from_directory(validation_dir,\n",
    "                                                                shuffle= True,\n",
    "                                                                target_size = (500,333), \n",
    "                                                                color_mode='rgb',\n",
    "                                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 769 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test set / Hold out Set                                                               \n",
    "test_set = image.ImageDataGenerator(rescale = 1/255).flow_from_directory(test_dir,\n",
    "                                                                shuffle = False, \n",
    "                                                                target_size = (500,333), \n",
    "                                                                color_mode='rgb',\n",
    "                                                                class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will run a very simple model to get an idea of a baseline, or a starting point to really work from. The metrics I am most interested in is recall as I would much rather get a bad photo mixed in with the good ones occasionally, rather than a good one tossed out with the bad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vanilla model \n",
    "\n",
    "HEIGHT = 500\n",
    "WIDTH = 333\n",
    "DEPTH = 3\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, 3, activation = 'relu', padding = 'same', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_model.compile(loss='binary_crossentropy',  \n",
    "                optimizer=optimizers.RMSprop(lr=.0001),\n",
    "                metrics = ['binary_accuracy', 'Recall', 'Precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62/62 [==============================] - 334s 5s/step - loss: 0.3441 - binary_accuracy: 0.8920 - recall: 0.0104 - precision: 0.0909 - val_loss: 0.8603 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 355s 6s/step - loss: 0.3286 - binary_accuracy: 0.9012 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.8538 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 300s 5s/step - loss: 0.3330 - binary_accuracy: 0.9012 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.8114 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 298s 5s/step - loss: 0.3287 - binary_accuracy: 0.9012 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.8265 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 296s 5s/step - loss: 0.3308 - binary_accuracy: 0.9012 - recall: 0.0000e+00 - precision: 0.0000e+00 - val_loss: 0.8405 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00 - val_precision: 0.0000e+00\n",
      "Total Time Elapsed:  27  minutes  1  seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timer to keep track of how long model is running for, not using class weights for this model\n",
    "start = timer()\n",
    "\n",
    "vanilla = model.fit(train_set, epochs = 5,\n",
    "                            validation_data = validation_set)\n",
    "end = timer()\n",
    "\n",
    "# Take difference of time \n",
    "elapsed = end - start\n",
    "print('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary, Evaluation, and Prediction on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 498, 331, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 249, 165, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 247, 163, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 123, 81, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 123, 81, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 123, 81, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 61, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 59, 38, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 29, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 9, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1835264   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,335,905\n",
      "Trainable params: 2,335,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vanilla_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 26s 1s/step - loss: 0.4752 - binary_accuracy: 0.8375 - recall: 0.0000e+00 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4751628637313843, 0.8374512195587158, 0.0, 0.0]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_model.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_model.save('SCRIPTS/model_script\\assets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Model with Class Weights \n",
    "\n",
    "So now that I have an idea, let's see if weighting the classes helps with the scores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighting the classes \n",
    "For later usage, we will weight the classes to help with class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5547984099943214, 1: 5.062176165803109}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "weights = compute_class_weight('balanced', [0, 1], train_set.classes)\n",
    "weights = dict(zip([0, 1], weights))\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, 3, activation = 'relu', padding = 'same', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss ='binary_crossentropy',  \n",
    "                optimizer = optimizers.RMSprop(lr = 0.0001), \n",
    "                weighted_metrics = 'Recall',\n",
    "                metrics = 'binary_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "62/62 [==============================] - 297s 5s/step - loss: 0.7444 - binary_accuracy: 0.6351 - recall: 0.3316 - val_loss: 0.6712 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "62/62 [==============================] - 298s 5s/step - loss: 0.7149 - binary_accuracy: 0.5440 - recall: 0.4352 - val_loss: 0.6961 - val_binary_accuracy: 0.3181 - val_recall: 1.0000\n",
      "Epoch 3/5\n",
      "62/62 [==============================] - 296s 5s/step - loss: 0.7052 - binary_accuracy: 0.5179 - recall: 0.4974 - val_loss: 0.6553 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "62/62 [==============================] - 295s 5s/step - loss: 0.7135 - binary_accuracy: 0.4816 - recall: 0.5078 - val_loss: 0.6577 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "62/62 [==============================] - 295s 5s/step - loss: 0.7168 - binary_accuracy: 0.5261 - recall: 0.3782 - val_loss: 0.6887 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00\n",
      "Total Time Elapsed:  25  minutes  17  seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timer to keep track of how long model is running for, not using class weights for this model\n",
    "start = timer()\n",
    "\n",
    "weighted_vanilla = model.fit(train_set, epochs = 5, class_weight = weights,\n",
    "                            validation_data = validation_set)\n",
    "end = timer()\n",
    "\n",
    "# Take difference of time \n",
    "elapsed = end - start\n",
    "print('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary, Evaluation, and Prediction on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 498, 331, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 249, 165, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 247, 163, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 123, 81, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 123, 81, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 123, 81, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 61, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 59, 38, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 29, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 9, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1835264   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,335,905\n",
      "Trainable params: 2,335,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "weighted_vanilla.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 26s 1s/step - loss: 0.4752 - binary_accuracy: 0.8375 - recall: 0.0000e+00 - precision: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4751628637313843, 0.8374512195587158, 0.0, 0.0]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_vanilla.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_vanilla.save('SCRIPTS/weighted_vanilla\\assets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 500\n",
    "WIDTH = 333\n",
    "DEPTH = 3\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation = 'relu', input_shape=(HEIGHT, WIDTH, DEPTH)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(128, kernel_size=(3, 3), activation=\"sigmoid\", padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "model.add(layers.Conv2D(256, kernel_size=(3, 3), activation=\"sigmoid\", padding=\"same\"))\n",
    "model.add(layers.MaxPooling2D())\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(256, activation=\"relu\"))\n",
    "model.add(layers.Dense(256, activation=\"sigmoid\"))\n",
    "model.add(layers.Dropout(0.25))\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',  \n",
    "                optimizer=optimizers.RMSprop(lr= 0.0001),\n",
    "                metrics = ['accuracy', 'binary_accuracy', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "62/62 [==============================] - 332s 5s/step - loss: 0.7058 - accuracy: 0.5901 - binary_accuracy: 0.5901 - recall: 0.4560 - val_loss: 0.7252 - val_accuracy: 0.3181 - val_binary_accuracy: 0.3181 - val_recall: 1.0000\n",
      "Epoch 2/10\n",
      "62/62 [==============================] - 372s 6s/step - loss: 0.7055 - accuracy: 0.5302 - binary_accuracy: 0.5302 - recall: 0.4611 - val_loss: 0.7041 - val_accuracy: 0.3181 - val_binary_accuracy: 0.3181 - val_recall: 1.0000\n",
      "Epoch 3/10\n",
      "62/62 [==============================] - 472s 8s/step - loss: 0.7156 - accuracy: 0.4969 - binary_accuracy: 0.4969 - recall: 0.4611 - val_loss: 0.6674 - val_accuracy: 0.6819 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "62/62 [==============================] - 622s 10s/step - loss: 0.7128 - accuracy: 0.5507 - binary_accuracy: 0.5507 - recall: 0.3679 - val_loss: 0.7171 - val_accuracy: 0.3181 - val_binary_accuracy: 0.3181 - val_recall: 1.0000\n",
      "Epoch 5/10\n",
      "62/62 [==============================] - 618s 10s/step - loss: 0.7027 - accuracy: 0.5368 - binary_accuracy: 0.5368 - recall: 0.4819 - val_loss: 0.7216 - val_accuracy: 0.3181 - val_binary_accuracy: 0.3181 - val_recall: 1.0000\n",
      "Epoch 6/10\n",
      "62/62 [==============================] - 661s 11s/step - loss: 0.7042 - accuracy: 0.4780 - binary_accuracy: 0.4780 - recall: 0.5544 - val_loss: 0.6949 - val_accuracy: 0.3883 - val_binary_accuracy: 0.3883 - val_recall: 0.8514\n",
      "Epoch 7/10\n",
      "62/62 [==============================] - 745s 12s/step - loss: 0.7035 - accuracy: 0.4882 - binary_accuracy: 0.4882 - recall: 0.5233 - val_loss: 0.6497 - val_accuracy: 0.6819 - val_binary_accuracy: 0.6819 - val_recall: 0.0000e+00\n",
      "Epoch 8/10\n",
      "62/62 [==============================] - 853s 14s/step - loss: 0.7044 - accuracy: 0.5742 - binary_accuracy: 0.5742 - recall: 0.4041 - val_loss: 0.6904 - val_accuracy: 0.6146 - val_binary_accuracy: 0.6146 - val_recall: 0.2748\n",
      "Epoch 9/10\n",
      "62/62 [==============================] - 459s 7s/step - loss: 0.7019 - accuracy: 0.5512 - binary_accuracy: 0.5512 - recall: 0.4715 - val_loss: 0.7015 - val_accuracy: 0.3266 - val_binary_accuracy: 0.3266 - val_recall: 0.9820\n",
      "Epoch 10/10\n",
      "62/62 [==============================] - 442s 7s/step - loss: 0.7034 - accuracy: 0.4775 - binary_accuracy: 0.4775 - recall: 0.5492 - val_loss: 0.6903 - val_accuracy: 0.5874 - val_binary_accuracy: 0.5874 - val_recall: 0.3243\n",
      "Total Time Elapsed:  94  minutes  51  seconds\n"
     ]
    }
   ],
   "source": [
    "# Start timer to keep track of how long model is running for\n",
    "start = timer()\n",
    "\n",
    "model_script = model.fit(train_set, epochs = 10, class_weight = weights,\n",
    "                            validation_data = validation_set)\n",
    "end = timer()\n",
    "\n",
    "# Take difference of time \n",
    "elapsed = end - start\n",
    "print('Total Time Elapsed: ', int(elapsed//60), ' minutes ', (round(elapsed%60)), ' seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary, Evaluation, and Prediction on Unseen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 498, 331, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 249, 165, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 247, 163, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 123, 81, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 123, 81, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 123, 81, 64)       18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 61, 40, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 59, 38, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 29, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 29, 19, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 9, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 14, 9, 256)        295168    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 7168)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1835264   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,335,905\n",
      "Trainable params: 2,335,905\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_script.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 31s 1s/step - loss: 0.6877 - accuracy: 0.6151 - binary_accuracy: 0.6151 - recall: 0.2160\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6877250075340271,\n",
       " 0.6150845289230347,\n",
       " 0.6150845289230347,\n",
       " 0.2160000056028366]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_script.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_script.predict(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: SCRIPTS/model_iv\u0007ssets/assets\n"
     ]
    }
   ],
   "source": [
    "model_script.save('SCRIPTS/model_script\\assets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_ = model_script.history\n",
    "epochs = model_script.epoch\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(epochs, model_['loss'], label='Training loss')\n",
    "plt.plot(epochs, model_['val_loss'], label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "    \n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 769 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = image.ImageDataGenerator(rescale = 1/255).flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(500, 333),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size = 32,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 19s 759ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict_generator(test_generator,verbose=1)\n",
    "predicted_class_indices=np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
